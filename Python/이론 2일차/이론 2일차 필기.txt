p31

머신러닝 특징

어떤 x가 들어왔을 때 h(x)가 특징 값이다. x -> h(x) 본래의 값과 조금 다르다.

예를 들어 데이터들이 정렬 또는 분류되었을 때(h(x)에 의해서), 

ex) xoxoxoxxxo -> xxxxx oooo

위 분류는 선을 하나만 그어도 구분이 되기 때문에 좋은 특징이다.
즉 선으로 분류가 되는 특징은 좋은 특징이다 - 효율성이 좋음

선형분리가 안되지만 그나마 비선형으로 분리 가능해도 괜찮은 편이다.
그러나 비선형으로 표현하는 것 자체가 함수로 나타내기 어렵다.

나쁜특징은 위 2가지에 모두 해당이 안되는 겹쳐지는 특징이다.

또한 상관관계가 높은 특징이 존재한다.

원뿔

trade off 효율성은 뛰어나나 정확도가 떨어지는 기술 == 근사화

멀티 모달특성을 가진 특성

- 사람은 맛을 볼 때 미각에만 의지하지 않고, 미각 후각 시각에도 영향을 받는다.
-> 멀티 모델 시스템

어떠한 하나의 특징만 가지고서는 구분할 수 없다.
다수의 선으로 구분지어야지만 가능.

비선형 분리로도 표현이 가능하나, 비선형의 특징에 따라 복잡도가 심해진다.



p 32

왜 머신러닝이 필요한가?

데이터가 있을 때, 초창기에는 데이터의 기본 정보를 모두 기입하고 매칭하는 방법을 선택하였다.
그러나 복잡한 데이터들의 경우 정의를 하기가 쉽지 않아 분류가 어렵다.

사람 한 명의 얼굴에도 표정이 정말 다양하므로 같은 사람을 서로 다른 사람으로 판단하는 경우가 있다.

표정, 조명, 악세서리 착용 등에 따라 표현 방식이 다르기에 매칭 시스템은 데이터 분류가 어렵다.

얼굴 인식 - 제일 어려운 바이오메트릭스 중 하나이다.
화장, 헤어스타일, 얼굴 각도 등

홍채 인식 - 사용자들의 거부감

p 33

머신러닝의 적용 분야

지문 , 얼굴, 홍채, 음성, 서명, 손, 걸음걸이, 열화상 , 다중

의료정보 , 자연어 , 문자/문서, 불량품 자동 인식, 생물정보학, 보안감시, 센서 데이터 분석, 영상인식, 군사용 타켓 판별 , 금융데이터 분석 
 

머신러닝의 구분

지도학습 (교사 학습)
supervised learning

기계에게 정답이 무엇인지를 알려주면서 학습 (스스로 채점해 볼 수 있다)
어떤 데이터가 정확하게 주어져 있고 옳고 그름을 따져야할 때 편하다.

분류 문제에 있어서 효과적이다


비지도 학습
unsupervised learning

정답을 별도로 알려주지 않고 데이터 자체의 특성을 바탕으로 학습
학생마다 어떤 특성을 중시하는 지에 따라 그룹을 나누는 방법이 다르다.
자체적으로 기준을 잡고 그룹을 나누어간다.
각각이 다른 특성들을 잡는 특징이 있다.


강화 학습
reinforcement learning

행동에 따른 보상을 주므로써 강화해나가는 학습

기계가 주어진 상태에 대해 최적의 행동을 선택하는 학습
학습 데이터 대신 주어진 상태에 맞춘 행동의 결과에 대한 보상을 주고 이 보상을 이용하여 성능 향상

준지도 학습
semi supervised learning
정답이 있는 데이터와 정답이 없는 데이터를 모두 학습에 사용


p 34

지도 학습의 종류
분류 - 예측

주어진 타겟 값에 대해 분류 하거나 예측하는데에 용이하다.

분류 문제와 회귀 문제로 구분되어진다.

타겟 값(y)이 라벨링 되어지면 분류에 해당된다.
타겟 값(y)이 실수 값으로 주어지면 회귀에 해당된다.

선형 회귀

h(x) = w1x + w2
w1과 w2를 찾는 방식

학습 데이터를 좌표계로 표현하고 직선을 긋고 분류를 시작함
두 직선을 긋고 오류의 크기를 비교

오류, 오차의 크기는 선을 그은 기준에 따라 음수,양수 모두 출현하므로 에러값 E를 구할 때 값을 제곱해주고 전체 값을 합해준다.(오차의 개수를 확인하기 위해서다)

Gredent decent 방법을 사용하여 w2값을 구하기 때문에 미분이 가능해야하므로 절댓값은 사용하지 않는다.





p 35

비지도 학습의 종류
군집화
- 계층적 군집
데이터들을 가까이 있는 것들끼리 묶어가는 것

1. 응집형 군집 : 샘플들간의 거리를 계산해서 그룹화 시킨다.
2. 분리형 군집 : 한 개의 그룹에서 여러개의 그룹으로 나뉘는 그룹화 형태

- 포인터 할당 군집
ex) 3개(n개)의 기준을 잡고 그룹화를 시작 3개의 기준은 Seed라고 불리며 Seed로 부터 거리를 계산하여 서로 가까이 있는 것들을 그룹화한다.


샘플 간의 거리 함수에 대한 공리

유클리디안 거리
- 직선 거리
	직표좌표계에서 직선 거리를 파악해서 계산한다.
맨하탄 거리
- 직선 거리
 	단 피타고라스의 c 거리가 아닌 a,b값을 거쳐서 가는 절댓값 거리
코사인 거리
- 원점으로부터 값을 연결하고 생기는 각도 -> 사잇값으로 계산
- 각도에 따라 거리가 계산된다.
사잇값이 0일 경우 동질

거리가 다양한 만큼 사용하려면 거리에 대한 조건을 맞춰야한다.
1. 거리는 겹쳐진 두 점 간의 거리는 0이다
2. x , y의 거리는 y , x 거리와 같아야한다.
3. x,y,z 3개의 점이 있는데, 한 점을 거쳐서 다른 점에 도착할 때 그 거리는 같거나 그 이상 이어야한다. 

차원축소 (Dimensionality Reduction)

투영
 - projection
 - 만일 1차원 공간에 데이터를 표현하고 싶다면 2차원의 데이터를 projection화 한다.
  간단히 빛을 비추어 생기는 그림자 값이라 이해한다.

매니폴드 학습

강화학습 종류
보상 - 대표적으로 게임 , 자율주행 네비게이션

데이터 분류 대상이 있는 것이 아닌, 에이전트라는 기계가 행동하였을 때 보상을 받는 방식으로 학습을 한다.

행동을 하게 되면 환경에 변화를 주게된다.
예시) 게임에서 조이스틱을 움직이는 순간 주변 상태가 업데이트된다.
업데이트 된 상태에서 에이젼트가 변화하게 된다.

보상이 +되는 형식으로 학습하며 강화가 되는 형태이다.

에이전트, 행위, 환경, 상태, 보상, 정책

어떤 행위를 할 것인가? -> 정책
정책을 세울 때 딥러닝을 사용하기도 한다.


준지도 학습

정답이 있는 데이터와 정답이 없는 데이터를 모두 학습에 사용




p 35 데이터 집합 구성

데이터를 사용하는 데에 있어 시점이 다르다

검증 데이터 validation data
테스트 데이터 test data

파라미터
모델 내부에서 결정되는 변수
데이터로부터 결정

하이퍼 파라미터
모델링할 때 사용자가 직접 결정
정해진 최적의 길은 없으나, 주로 경험 법칙(rules of thumb)에 의해 결정

ex) 학습률(NN) sigma(SVM) k값(KNN) 등


p 37

교차검증 (cross validation)

k-fold 교차 검증

데이터의 수가 적을 때 사용한다.

집합 X1 한 개를 테스트로 사용, 나머지를 트레이닝으로 사용
다음으로 집합 X2 한 개를 테스트로 사용, 나머지를 트레이닝으로 사용

이를 K개 테스트로 사용하여 전체적인 집합에 대해 테스트를 한다.
안정적인 모델일 경우, 평균값이 높으면서 표준편차가 작다.

만일 K = N 일 경우 (데이터 개수) 1개의 데이터를 제외하고 모두 트레이닝 방식을 N번 반복하며 이를 K-fold N-special이라고 한다.


p 38


배치 학습과 온라인 학습

배치 학습

모든 학습데이터를 한꺼번에 학습 -> 간단함
일반적으로 오프라인에서 수행 -> offline learning
추가로 확보된 데이터를 학습에 활용하려면 전체 데이터로 다시 학습
*시간과 자원이 많이 소요 -> 속도가 많이 느림
Epoch = 배치학습 주기 

배치 학습은 결과값이 만족할 때 까지 반복하게 된다. -> Epoch의 크기


온라인 학습

배치 학습시 데이터가 너무 많으니 데이터를 나누어서 학습하자.

데이터를 미니 배치 단위로 나누어 순차적으로 학습
학습 단계가 빠르고 비용이 적음
학습이 끝난 데이터는 제거가 가능하다 -> 메모리 절약
학습률 설정이 중요 -> 학습률을 높이면 , 시스템이 데이터에 빠르게 적응
	             -> 학습률을 낮추면, 새로운 데이터에 덜 민감






p 39 ~ 42


Variance 예측된 값들이 서로 얼마나 떨어져있는가
Bias 실제값에서 멀어진 척도


오버피팅

많은 공통 특성(feature) 이외에 지엽적인 특성까지 반영하여 세밀하게 학습된 결과 새로운 데이터에 대해서는 예측하지 못하는 모델
너무 세밀하게 학습하여 데이터를 분별하지 못 함

높은 variance
낮은 bias

feature가 많아져 high variance하여 예측값들이 떨어짐

해결법

validation set을 갖추고 k-fold cross validation을 사용하여 train set과 비교하기  (train보다 낮을 경우 overfiting)
validation set의 accurancy가 train보다 낮다면 Regularization을 계속해서 반복

조기종료
50epoch를 준 상태에서 특정 epoch (예를 들어 30) 에서 validation set의  accuracy가 제일 높았다면 30에서 stop하는 것을 조기종료 early stopping 이라고 한다.
 
DropOut
train과정 중 몇 개의 뉴런을 쉬도록 만드는 것


책 내용

데이터증식
 더 많은 데이터 수집
 기존 데이터 변형, 노이즈 추가

모델의 복잡도 감소
 모델의 파라미터 수 감소
 신경망의 경우 hodden layer 수 감소 등

드롭 아웃(신경망 학습 시)
 신경망의 일부를 사용하지 않음

조기 종료 (iteration이 포함된 학습 시)

정규화
 L2 정규화
 Gradient Descent
 Weight dacay - 특정 가중치가 비정상적으로 커져서 학습에 영향을 주는 것을 방지

 
 L1 정규화






언더피팅

많은 공통된 특성이 있음에도 불구하고 한 가지 특성만으로 학습 시킨 경우
테스팅 단계에서 새로운 데이터를 너무 잘 예측해버리는 모델

너무 간단히 학습하여 데이터를 분별하지 못 함 

높은 Bias
낮은 variance

 feature가 너무 적어 high bias 하여 실제값과 떨어짐

해결법 

feature를 더 많이 반영하여 variance 높이기
variance가 높은 머신러닝 모델 사용하기 -> Decision Tree kNN SVM 등


즉 feature 반영이 너무 높으면 오버피팅 너무 낮으면 언더피팅



-----------

p 43



회귀 모델의 성능 평가

MAE
모델의 예측 값과 실제 값의 차이를 모두 더한 값
Outlier에 영향을 받음
실제 겂보다 크게 예측 되었는지 작게 예측되었는지 구분 못함

MSE
직관적이고 일반적으로 많이 사용
Outliner에 민감

RMSE
산출된 에러 값의 단위가 실제 값과 유사


분류모델의 성능 평가

심플 카운팅

독립적인 테스트 데이터 샘플을 모두 평가해서 제대로 분류된 샘플의 개수를 카운팅
분류율
	P(C) = Nct / Nt
에러율
	P(E) = 1-P(C)

직관적이고 간단함


TP (True Positive) : 실제 Pos인 샘플을 Pos로 예측 (정답)
FP (False Postive) : 실제 Neg인 샘플을 Pos로 예측 (오답)
FN (False Negative) : 실제 Pos인 샘플을 Neg로 예측 (오답)
TN (True Negative) : 실제 Neg인 샘플을 Neg로 예측 (정답)


Recall = TP / TP + FN

Precision = TP / TP + FP

Specificity = TN / TN + FP

Accuracy = TP + TN / TP + TN + FP +FN

F1 Score = 2 x precision x recall / (precision + recall) 



p 46

인공지능 기술의 역사

1 - 인공지능의 탄생 (1943 ~ 1956)
	인공지능 분야로 인정받은 최초 연구 소개 (1943)
	튜링 테스트 (1950)
	다트머스 컨퍼런스 (1956)
	
2 - 인공지능의 황금기 (1956 ~ 1974)
	반복적인 수학 계산을 넘어 여러 성공적인 프로그램들 개발
	컴퓨터 프로그램에 대한 큰 기대와 함께 인공지능 기술에 대한 지나친 낙관
	정부의 과감한 투자

3 - 첫 번째 암흑기 (1974 ~ 1980)
	1960년대 후반 현실적 어려움 직면
		범용성 방법론 연구 - 적합하지 않은 정보 사용
		컴퓨터 능력의 한계 : 불충분한 메모리와 처리 속도
		현실 묹를 단순화한 장난감 수준의 프로그램
	인공지능 연구에 대한 지원 중단
		연구 부진에 대한 실망
		AI 연구 지원 중단
		마빈 민스키의 퍼셉트론 한계 증명

4 - 재도약기 (1980 ~ 1987)
	전문가 시스템의 발전
		범용성 문제보다 전문 지식이 필요한 전형적인 영역으로 문제를 체한 하고 추론 단계 사용
	지식 혁명
		지식 기반 시스템과 지식 엔지니어링 발전
		Cyc 일상적인 사실들을 포함한 거대한 데이터베이스를 만들어 상식 문제 해결을 시도
	신경망 이론의 복귀
		컴퓨터 기술과 신경 과학의 발달에 따라 신경망에 대한 관심 재부상
		홉필드 신경망, 자기조직 맵, 강화학습 ,역전파 학습 알고리즘
		1990년대에 광학문자인식, 음성인식 등에서 상업적 성공
	
5 - 안공지능의 두 번째 겨울 (1987 ~ 1993)
	전문가 시스템의 한계
		비싼 하드웨어와 LISP , PROLOG 등 특별한 AI 언어로 개발
		특정 전문 영역에 국한된 사용 분야	
		애플이나 IBM 데스크탑 컴퓨터 발전
	연구방향의 전환
		DARPA : AI 대신 즉각적인 결과를 낼 수 있는 프로젝트에 직접적인 투자
		일본의 5세트 프로젝트의 성과 부진
		슈퍼컴퓨터와 시뮬레이션 분야로 연구 방향 전환

6 - 정체기 (1990 ~ 2010)
	1980년대 중반 신경망 재탄생과 함께 다양한 기계학습 연구 시도
		학습 알고리즘의 부재 및 연산량의 문제로 대규모 신경망 구현 불가
		경험해 본 적 없는 데이터를 처리하기 위해 컴퓨터를 학습시키는 알고리즘
		알고리즘을 이용하여 데이터의 패턴을 파악하고 이 패턴을 이용하여 예측 모델 구축
		적응성을 갖춘 알고리즘	
			기존 데이터와 모양과 성격이 변해도 학습을 바탕으로 솔루션을 찾음
		커널 방법, 서포트 벡터 머신, 랜덤 포레스트 등 다양한 기계학습 알고리즘 및 특징 추출 방법 개발
	지능형 에이전트
		1990년대부터 지능형 에이전트라는 시스템이 두각
		에이전트 : 독자적으로 존재하지 않고 어떤 환경의 일부 또는 그 안에서 동작하는 시스템
		센서를 이용하여 주변 환경을 감지하고 액추에이터를 이용하여 적절한 행동 수행
		eg. 질병 진단 시스템, 자율주행 자동차

7 - 세 번째 황금기 딥러닝의 시대 (2010 ~ 현재)
	인간의 뇌를 모방한 딥러닝 네트워크의 구현
	다양한 분야에 딥러닝 네트워크 적용 확장
		컴퓨터 비전 : VGG , EfficientNet, Unet 등 
			영상인시그 분할, 검출 , 생체인식 등
		자동 음성 인식
			MS 코타나 구글 나우 등
		자연어 처리 : RNN , LSTM , 어텐션 , 트랜스포머 , BERT 등
			자동번역 감정 분석 정보 검색 챗봇 등
	



P 52


딥러닝

머신러닝 알고리즘 중 선형 또는 비선형 transform 함수로 구성된 processing layer 를 다층으로 갖고있는 deep graph를 사용하여 입력으로부터 고차원적인 추상화를 목적으로 하는 것들의 집합


성능적인 측면

Layer의 개수가 적으면 좋은 성능을 내기 어려움
Layer의 개수가 많을 시, 심층부 layer까지 잘 학습시키는 학습 알고리즘의 부재

practical한 측면

overfitting 을 피하기 위해서는 많은 수의 laveled data 필요
학습해야하는 parameter (각 뉴런이 가지고있는 weight들과 bias)가 너무 많아 실제적으로 학습에 걸리는 시간이 너무 길었음







