{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2sutb5CJDtBA"
   },
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# 런타임 -> 런타임 유형 변경 -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AIoIJ7H6Dz03"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _path: 지정된 모듈을 찾을 수 없습니다.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MNIST\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmartist\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\collections.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_api, _path, artist, cbook, cm, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, _docstring,\n\u001b[0;32m     20\u001b[0m                hatch \u001b[38;5;28;01mas\u001b[39;00m mhatch, lines \u001b[38;5;28;01mas\u001b[39;00m mlines, path \u001b[38;5;28;01mas\u001b[39;00m mpath, transforms)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# \"color\" is excluded; it is a compound setter, and its docstring differs\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# in LineCollection.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _path: 지정된 모듈을 찾을 수 없습니다."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1xvErfbEhsb",
    "outputId": "81d3bb19-2fdc-4e42-a652-2c9c6e47d8ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 되는지 확인\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "d04Akb2cEjSc"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "xmaIaeOFE3vT"
   },
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root = 'MNIST_data/' , train = True , transform=transforms.ToTensor(), download=True)\n",
    "train_dataset = MNIST(root = 'MNIST_data/' , train = True , transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AygdgR3ZFV-X",
    "outputId": "a7cdac01-34a0-4005-e375-4f13c8f6652c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: MNIST_data/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "LZR549GGFj3Q"
   },
   "outputs": [],
   "source": [
    "# Datalodaer 생성\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset ,\n",
    "                           batch_size = 128 ,shuffle = True)\n",
    "train_loader = DataLoader(dataset = train_dataset ,\n",
    "                           batch_size = 128 ,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Csyzy4QbF69P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVaWbmWaGRl7"
   },
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "LvUZHhOaGDiS"
   },
   "outputs": [],
   "source": [
    "# Numpy > Tensor\n",
    "\n",
    "z = torch.empty(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSni4gXyGlDc",
    "outputId": "a4f45a91-a70d-4344-d498-300259c0b66a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1r32026uGvfe",
    "outputId": "b04a5e51-6ecd-49ad-d413-ed3cb971ed59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64) torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((5,2))\n",
    "print(a)\n",
    "\n",
    "# tensor로 변환\n",
    "\n",
    "b = torch.from_numpy(a)\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvgxvGMMHB4y",
    "outputId": "b4f5e4c1-356f-42f8-9416-12be8ff00854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# tensor > numpy\n",
    "numpy_arr = b.numpy()\n",
    "print(numpy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "12_tsjxAHKcr"
   },
   "outputs": [],
   "source": [
    "# MNIST 데이터 셋을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "9BIYdp8FHQNz",
    "outputId": "8926d199-ab2c-42da-f6b5-261649400583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape =  (1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 하나의 이미지만 가져오기\n",
    "img = train_dataset[0][0].numpy()\n",
    "print('img shape = ' , img.shape)\n",
    "plt.imshow(img[0 ], cmap = 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "5Tj9OrCaHt0i"
   },
   "outputs": [],
   "source": [
    "# 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "VL3by2KLHzVc"
   },
   "outputs": [],
   "source": [
    "# sequential\n",
    "\n",
    "mnist_fo_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=28*28*1 , out_features=256) ,\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(in_features=256 , out_features=10) ,\n",
    "    nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RuvIg9mIh6-",
    "outputId": "3c49a215-bb78-4090-a27a-43d0bd2918be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (2): Sigmoid()\n",
       "  (3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (4): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device\n",
    "# 모델을 device로 전달\n",
    "# cpu에 만들어지고 gpu로 넘겨서 연산을 하도록 한다.\n",
    "\n",
    "mnist_fo_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "p_ErhgiVIecu"
   },
   "outputs": [],
   "source": [
    "# pass는 디버깅\n",
    "\n",
    "from  torch import optim\n",
    "\n",
    "# time 패키지\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def train(model, train_loader) :\n",
    "  # 시간 재기 시작\n",
    "  start_time = time.time()\n",
    "\n",
    "  epoche = 10\n",
    "  optimizer = optim.Adam(model.parameters() ,  lr = 0.0001)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  for epoch in range(epoche) :\n",
    "    # model 학습이 가능하도록 모드를 변경\n",
    "    model.train()\n",
    "    print(f\"epochs :{str(epoch+1)}/{str(epoche)}\")\n",
    "\n",
    "    for samples in train_loader :\n",
    "        x_t , y_t = samples\n",
    "        # print('pass 01 ')\n",
    "        # 데이터를 cuda(gpu)로 보낸다\n",
    "        x_t, y_t = x_t.to(device) , y_t.to(device)\n",
    "        # print('pass 02 ')\n",
    "        # predict\n",
    "        pred = model(x_t)\n",
    "        # print('pass 03 ')\n",
    "        # loss 구하기\n",
    "        loss = criterion(pred , y_t)\n",
    "        # print('pass 04 ')\n",
    "        # optimizer를 이용해서 학습\n",
    "        optimizer.zero_grad()\n",
    "        # print('pass 05 ')\n",
    "        # 역전파 # 기울기 구하기\n",
    "        loss.backward()\n",
    "        # print('pass 06 ')\n",
    "        # 기울기 적용\n",
    "        optimizer.step()\n",
    "        # print('pass 07 ') \n",
    "        # 하나의 epoch에 대해 학습이 끝난 후\n",
    "\n",
    "     # 모델 평가\n",
    "    model.eval()\n",
    "    # print('pass eval')\n",
    "    correct = 0\n",
    "    for samples in train_loader :\n",
    "      xx , yy = samples \n",
    "      # print('pass sample')\n",
    "      xx, yy = xx.to(device) , yy.to(device)\n",
    "      # print('pass device')\n",
    "      pred = model(xx) #  모델 predict\n",
    "      # print('predict')\n",
    "      _, predicted = torch.max(pred, 1)\n",
    "      correct += predicted.eq(yy.data).sum()\n",
    "      # print('pass correct')\n",
    "    #print('loop end pass')\n",
    "    print(f'train_accuracy : {(100 * correct / len(train_loader.dataset)).item()}')\n",
    "\n",
    "  # 시간 재기 끝\n",
    "  end_time = time.time()\n",
    "  지난시간 = end_time - start_time\n",
    "  분 = int(지난시간 // 60 )\n",
    "  초 = int(지난시간 ** 60)\n",
    "\n",
    "  print(f'학습 시간 : {분}분 {초}초')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBzVfopyLEY3",
    "outputId": "78ea2946-c82c-4cb9-9223-b838b5186fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :1/10\n",
      "train_accuracy : 93.06999969482422\n",
      "epochs :2/10\n",
      "train_accuracy : 93.19667053222656\n",
      "epochs :3/10\n",
      "train_accuracy : 93.37833404541016\n",
      "epochs :4/10\n",
      "train_accuracy : 93.51667022705078\n",
      "epochs :5/10\n",
      "train_accuracy : 93.66333770751953\n",
      "epochs :6/10\n",
      "train_accuracy : 93.79000091552734\n",
      "epochs :7/10\n",
      "train_accuracy : 93.93333435058594\n",
      "epochs :8/10\n",
      "train_accuracy : 94.04499816894531\n",
      "epochs :9/10\n",
      "train_accuracy : 94.17666625976562\n",
      "epochs :10/10\n",
      "train_accuracy : 94.26499938964844\n"
     ]
    }
   ],
   "source": [
    "train(mnist_fo_model , train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "k_uMLwWRXYSN"
   },
   "outputs": [],
   "source": [
    "# 우리가 만든 모델의 복잡도 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "0Nbzk3UtMNnZ"
   },
   "outputs": [],
   "source": [
    "# 모델의 복잡도 판단\n",
    "# 훈련가능한 파라미터\n",
    " # 훈련가능하지 않은 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "did9HeF_nbpY"
   },
   "outputs": [],
   "source": [
    "def 복잡도계산(model) :\n",
    "  pp = 0 \n",
    "  # 모델에서 ㅍ파라미터를 하나씩 불러온다\n",
    "  for p in list(model.parameters()) :\n",
    "    nn = 1\n",
    "    # 각 파라미터의 수를 더해준다\n",
    "    for a in list(p.size()) :\n",
    "      nn = nn * a\n",
    "    pp += nn\n",
    "  return pp\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_f_qqka1ncJ9",
    "outputId": "66c7ced7-b37c-4583-ef56-e281e2e7c3dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203530"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "복잡도계산(mnist_fo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "SzaU1hWxncMu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rE5_aGZoQOO"
   },
   "source": [
    "# cnn 이용하여 모델  설계\n",
    "\n",
    "cnn 합성곱연사을 이용한 모델\n",
    "이미지에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "_TnfLfLHncO0"
   },
   "outputs": [],
   "source": [
    "mnist_cnn_model = nn.Sequential(\n",
    "    # input 1x28x28\n",
    "    nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=0),\n",
    "    nn.ReLU(),\n",
    "    # ===== convolution layer 2개 완성 =====\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=24*24*8, out_features=48),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(in_features=48, out_features=10),\n",
    "    nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2KPoM_6TncRG",
    "outputId": "865380b9-fb15-4e13-8d2f-fce34655af2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203530"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "복잡도계산(mnist_fo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HND7jHFZvkEh",
    "outputId": "6e1daed1-0ba9-41da-c8c1-81ed30c0f113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :1/10\n",
      "train_accuracy : 69.99666595458984\n",
      "epochs :2/10\n",
      "train_accuracy : 80.9816665649414\n",
      "epochs :3/10\n",
      "train_accuracy : 82.96500396728516\n",
      "epochs :4/10\n",
      "train_accuracy : 84.2300033569336\n",
      "epochs :5/10\n",
      "train_accuracy : 90.04833221435547\n",
      "epochs :6/10\n",
      "train_accuracy : 91.14500427246094\n",
      "epochs :7/10\n",
      "train_accuracy : 91.8933334350586\n",
      "epochs :8/10\n",
      "train_accuracy : 92.55000305175781\n",
      "epochs :9/10\n",
      "train_accuracy : 93.11000061035156\n",
      "epochs :10/10\n",
      "train_accuracy : 93.57833099365234\n"
     ]
    }
   ],
   "source": [
    "# gpu에 모델을 넣어줌\n",
    "mnist_cnn_model.to(device)\n",
    "# 학습\n",
    "train(mnist_cnn_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "i6kDp0hkncTM"
   },
   "outputs": [],
   "source": [
    "#  Le Net 이라는 검증된 네트워크를 만들어보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "2Y-0h_vuncVd"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as r\n",
    "\n",
    "lenet = nn.Sequential(\n",
    "    nn.Conv2d(in_channels = 1 , out_channels = 6 , kernel_size = 5 , stride = 1) ,\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(kernel_size = 2) ,\n",
    "    nn.Conv2d(in_channels = 6 , out_channels = 16 , kernel_size = 5 , stride = 1) ,\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(kernel_size = 2) ,\n",
    "    nn.Conv2d(in_channels = 16 , out_channels = 120 , kernel_size = 4, stride = 1) ,\n",
    "    nn.Tanh(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=120 , out_features=84) ,\n",
    "    nn.Tanh() ,\n",
    "    nn.Linear(in_features= 84 , out_features=10),\n",
    "    nn.Softmax()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMF639jMtOrj"
   },
   "outputs": [],
   "source": [
    "복잡도계산()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6Q8OvJJsaeD",
    "outputId": "60957855-81cd-4185-c940-1c2b2e17895a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 76.30833435058594\n",
      "epochs :2/10\n",
      "train_accuracy : 88.38333129882812\n",
      "epochs :3/10\n",
      "train_accuracy : 90.08833312988281\n",
      "epochs :4/10\n",
      "train_accuracy : 91.30500030517578\n",
      "epochs :5/10\n",
      "train_accuracy : 92.28500366210938\n",
      "epochs :6/10\n",
      "train_accuracy : 93.1066665649414\n",
      "epochs :7/10\n",
      "train_accuracy : 93.78333282470703\n",
      "epochs :8/10\n",
      "train_accuracy : 94.4433364868164\n",
      "epochs :9/10\n",
      "train_accuracy : 94.84333801269531\n",
      "epochs :10/10\n",
      "train_accuracy : 95.30500030517578\n"
     ]
    }
   ],
   "source": [
    "# gp에다가 모델을 넘겨주기 위함\n",
    "lenet.to(device)\n",
    "# 학습을 진행\n",
    "train(lenet , train_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PotvvuMstK1E",
    "outputId": "848cfcd6-8088-4d46-93ce-ab67f93c4361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "              Tanh-2            [-1, 6, 24, 24]               0\n",
      "         AvgPool2d-3            [-1, 6, 12, 12]               0\n",
      "            Conv2d-4             [-1, 16, 8, 8]           2,416\n",
      "              Tanh-5             [-1, 16, 8, 8]               0\n",
      "         AvgPool2d-6             [-1, 16, 4, 4]               0\n",
      "            Conv2d-7            [-1, 120, 1, 1]          30,840\n",
      "              Tanh-8            [-1, 120, 1, 1]               0\n",
      "           Flatten-9                  [-1, 120]               0\n",
      "           Linear-10                   [-1, 84]          10,164\n",
      "             Tanh-11                   [-1, 84]               0\n",
      "           Linear-12                   [-1, 10]             850\n",
      "          Softmax-13                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.08\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(lenet , input_size = (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "bbPZtyVVte_b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# FashionMNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "t2V9WQ4Y3xQw"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtVWtgCV34Hf",
    "outputId": "3d72199f-7ec7-45fd-bb1e-21e70a03f628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 12393112.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 207704.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 3887324.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 20067171.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), # tensor 형태로 변환\n",
    "    transforms.Resize(48) # 48 x 48 이미지로 변환\n",
    "])\n",
    "\n",
    "train_dataset = FashionMNIST('./' , transform = fashion_mnist_transforms , train = True , download = True)\n",
    "test_dataset = FashionMNIST('./' , transform = fashion_mnist_transforms , train = False , download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "ZUo0QYBL4Qgn"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset\n",
    "                          , batch_size = 256\n",
    "                          , shuffle = True\n",
    "                          )\n",
    "test_loader = DataLoader(dataset = test_dataset\n",
    "                         , batch_size = 256\n",
    "                         , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "jmkxMb_55ErO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhuGZkGs5jaQ"
   },
   "source": [
    "# 모델 만들기\n",
    "총 7개의 convolution layer가 존재하도록 만들 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "xB6yo78U5Fne"
   },
   "outputs": [],
   "source": [
    "# 이미지 데이터 확인\n",
    "# train_dataset[0][0].shape\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class SimpleConvNet1(nn.Module):\n",
    "  def __init__(self) :\n",
    "    # 초기화_\n",
    "    super().__init__() # 부모 클래스 초기화\n",
    "    # 선언\n",
    "    # 시작 아웃풋 = 다음 인풋\n",
    "    self.CNN = nn.Sequential(\n",
    "        # stage1\n",
    "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.MaxPool2d(kernel_size=2 , stride =2)\n",
    "\n",
    "        # stage2\n",
    "        , nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.MaxPool2d(kernel_size=2 , stride =2)\n",
    "\n",
    "        # stage3\n",
    "        , nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3 , stride = 1 , padding = 'same')\n",
    "        , nn.ReLU(True)\n",
    "        , nn.MaxPool2d(kernel_size=4 , stride =4)\n",
    "    )\n",
    "\n",
    "    self.FC = nn.Sequential(\n",
    "        nn.Linear(64*3*3 , 256)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Dropout(p=0.2)\n",
    "        , nn.Linear(256 , 10)\n",
    "        , nn.Softmax()\n",
    "    )\n",
    "\n",
    "  # forward\n",
    "  def forward(self , inp) :\n",
    "    cnn_result = self.CNN(inp)\n",
    "    flatten = torch.flatten(cnn_result , 1)\n",
    "    fc_result = self.FC(flatten)\n",
    "    return fc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "hGpDTQdM5FvZ"
   },
   "outputs": [],
   "source": [
    "convent1 = SimpleConvNet1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KumdNYCa5FwW",
    "outputId": "835ce58a-3641-4f81-a1d1-8c332d86ec28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             160\n",
      "              ReLU-2           [-1, 16, 48, 48]               0\n",
      "            Conv2d-3           [-1, 16, 48, 48]           2,320\n",
      "              ReLU-4           [-1, 16, 48, 48]               0\n",
      "         MaxPool2d-5           [-1, 16, 24, 24]               0\n",
      "            Conv2d-6           [-1, 32, 24, 24]           4,640\n",
      "              ReLU-7           [-1, 32, 24, 24]               0\n",
      "            Conv2d-8           [-1, 32, 24, 24]           9,248\n",
      "              ReLU-9           [-1, 32, 24, 24]               0\n",
      "        MaxPool2d-10           [-1, 32, 12, 12]               0\n",
      "           Conv2d-11           [-1, 64, 12, 12]          18,496\n",
      "             ReLU-12           [-1, 64, 12, 12]               0\n",
      "           Conv2d-13           [-1, 64, 12, 12]          36,928\n",
      "             ReLU-14           [-1, 64, 12, 12]               0\n",
      "           Conv2d-15           [-1, 64, 12, 12]          36,928\n",
      "             ReLU-16           [-1, 64, 12, 12]               0\n",
      "        MaxPool2d-17             [-1, 64, 3, 3]               0\n",
      "           Linear-18                  [-1, 256]         147,712\n",
      "             ReLU-19                  [-1, 256]               0\n",
      "          Dropout-20                  [-1, 256]               0\n",
      "           Linear-21                   [-1, 10]           2,570\n",
      "          Softmax-22                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 259,002\n",
      "Trainable params: 259,002\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.23\n",
      "Params size (MB): 0.99\n",
      "Estimated Total Size (MB): 3.22\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "convent1.to(device)\n",
    "summary(convent1 , input_size = (1,48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_411jHyR5FxG",
    "outputId": "7429117d-d4b5-481c-a5b0-ef87d4749716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 69.87833404541016\n",
      "epochs :2/10\n",
      "train_accuracy : 75.87999725341797\n",
      "epochs :3/10\n",
      "train_accuracy : 77.91000366210938\n",
      "epochs :4/10\n",
      "train_accuracy : 78.52999877929688\n",
      "epochs :5/10\n",
      "train_accuracy : 80.39666748046875\n",
      "epochs :6/10\n",
      "train_accuracy : 81.78166961669922\n",
      "epochs :7/10\n",
      "train_accuracy : 81.82333374023438\n",
      "epochs :8/10\n",
      "train_accuracy : 83.49333190917969\n",
      "epochs :9/10\n",
      "train_accuracy : 83.84333801269531\n",
      "epochs :10/10\n",
      "train_accuracy : 83.94833374023438\n",
      "학습 시간 : 5분 871402390287682705873410680747973273141535962003763229905507875445081013699018095074962238472195189550525416842877236790041693339945711933280256450887680초\n"
     ]
    }
   ],
   "source": [
    "train(convent1 , train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "2MaX6c9K5Fx7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaCyhivvEP_i"
   },
   "source": [
    "# test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "D0LzzaMm5Fyq"
   },
   "outputs": [],
   "source": [
    "def test(model , loader) :\n",
    "  with torch.no_grad() :\n",
    "    # 이 안에 있는 것들은 기울기 계산을 안함\n",
    "    # 모델이 고정됨 , 평가하는 용도로 제격\n",
    "    model.eval() # 모델을 평가모드로 변경\n",
    "    correct = 0\n",
    "    for xx, yy in loader :\n",
    "      # xx : 데이터(이미지)\n",
    "      # yy : 정답\n",
    "      data , target = xx.to(device) , yy.to(device)\n",
    "      pred = model(data)\n",
    "      _, predicted = torch.max(pred , 1)\n",
    "      correct += predicted.eq(target.data).sum()\n",
    "\n",
    "  print(f'test accuracy {(100*correct / len(loader.dataset)).item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cq-m4Q_G5Fzj",
    "outputId": "a6d715a4-e6c1-4f2a-bf3c-441dbfc96771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 82.61000061035156\n"
     ]
    }
   ],
   "source": [
    "test(convent1 , test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "wTZ0cFb-5F0Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmmraM5JJ1it"
   },
   "source": [
    "# MNIST 훈련\n",
    "# SVHN이라는 데이터셋 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "izMhhT1mK1Zc"
   },
   "outputs": [],
   "source": [
    "# 이미지 데이터 확인\n",
    "# train_dataset[0][0].shape\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class SimpleConvNet2(nn.Module):\n",
    "  def __init__(self) :\n",
    "    # 초기화_\n",
    "    super().__init__() # 부모 클래스 초기화\n",
    "    # 선언\n",
    "    # 시작 아웃풋 = 다음 인풋\n",
    "    self.CNN = nn.Sequential(\n",
    "        # stage1\n",
    "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.MaxPool2d(kernel_size=2 , stride =2)\n",
    "\n",
    "        # stage2\n",
    "        , nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.MaxPool2d(kernel_size=2 , stride =2)\n",
    "\n",
    "        # stage3\n",
    "        , nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3 , stride = 1 , padding = 1)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3 , stride = 1 , padding = 'same')\n",
    "        , nn.ReLU(True)\n",
    "        , nn.MaxPool2d(kernel_size=4 , stride =4)\n",
    "    )\n",
    "\n",
    "    self.FC = nn.Sequential(\n",
    "        nn.Linear(64*3*3 , 256)\n",
    "        , nn.ReLU(True)\n",
    "        , nn.Dropout(p=0.2)\n",
    "        , nn.Linear(256 , 10)\n",
    "        , nn.Softmax()\n",
    "    )\n",
    "\n",
    "  # forward\n",
    "  def forward(self , inp) :\n",
    "    cnn_result = self.CNN(inp)\n",
    "    flatten = torch.flatten(cnn_result , 1)\n",
    "    fc_result = self.FC(flatten)\n",
    "    return fc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "107Pt6cc5F1O"
   },
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root = 'MNIST_data/' , train = True , transform = fashion_mnist_transforms,download = True)\n",
    "test_dataset = MNIST(root = 'MNIST_data/' , train = False , transform = fashion_mnist_transforms,download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "qB71o2Kl5F19"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset\n",
    "                          , batch_size = 256\n",
    "                          , shuffle = True)\n",
    "test_loader = DataLoader(dataset = train_dataset\n",
    "                          , batch_size = 256\n",
    "                          , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "KxwIOWqwK9eV"
   },
   "outputs": [],
   "source": [
    "convnet2 = SimpleConvNet1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAiFqCpK5F3u",
    "outputId": "49e6d2f7-486d-4a70-d1be-8bec63a8172e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             160\n",
      "              ReLU-2           [-1, 16, 48, 48]               0\n",
      "            Conv2d-3           [-1, 16, 48, 48]           2,320\n",
      "              ReLU-4           [-1, 16, 48, 48]               0\n",
      "         MaxPool2d-5           [-1, 16, 24, 24]               0\n",
      "            Conv2d-6           [-1, 32, 24, 24]           4,640\n",
      "              ReLU-7           [-1, 32, 24, 24]               0\n",
      "            Conv2d-8           [-1, 32, 24, 24]           9,248\n",
      "              ReLU-9           [-1, 32, 24, 24]               0\n",
      "        MaxPool2d-10           [-1, 32, 12, 12]               0\n",
      "           Conv2d-11           [-1, 64, 12, 12]          18,496\n",
      "             ReLU-12           [-1, 64, 12, 12]               0\n",
      "           Conv2d-13           [-1, 64, 12, 12]          36,928\n",
      "             ReLU-14           [-1, 64, 12, 12]               0\n",
      "           Conv2d-15           [-1, 64, 12, 12]          36,928\n",
      "             ReLU-16           [-1, 64, 12, 12]               0\n",
      "        MaxPool2d-17             [-1, 64, 3, 3]               0\n",
      "           Linear-18                  [-1, 256]         147,712\n",
      "             ReLU-19                  [-1, 256]               0\n",
      "          Dropout-20                  [-1, 256]               0\n",
      "           Linear-21                   [-1, 10]           2,570\n",
      "          Softmax-22                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 259,002\n",
      "Trainable params: 259,002\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.23\n",
      "Params size (MB): 0.99\n",
      "Estimated Total Size (MB): 3.22\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "convnet2.to(device)\n",
    "summary(convnet2 , (1,48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omSEAZ_k5F4z",
    "outputId": "88656c29-0592-4707-c54e-6c1dee4b0f7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy : 73.5683364868164\n",
      "epochs :2/10\n",
      "train_accuracy : 93.91333770751953\n",
      "epochs :3/10\n",
      "train_accuracy : 95.88833618164062\n",
      "epochs :4/10\n",
      "train_accuracy : 96.1433334350586\n",
      "epochs :5/10\n",
      "train_accuracy : 96.06666564941406\n",
      "epochs :6/10\n",
      "train_accuracy : 97.125\n",
      "epochs :7/10\n",
      "train_accuracy : 97.33833312988281\n",
      "epochs :8/10\n",
      "train_accuracy : 97.55667114257812\n",
      "epochs :9/10\n",
      "train_accuracy : 97.90666961669922\n",
      "epochs :10/10\n",
      "train_accuracy : 98.05166625976562\n",
      "학습 시간 : 5분 325328872444232372221692418253415070802000202093687015429291673706106244144895501277361982969045446250719713853003902455428032041130361551946286362525696초\n"
     ]
    }
   ],
   "source": [
    "train(convnet2, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7gtfYj95F6G",
    "outputId": "5c6da9f1-1cf3-467f-a063-f6628c8eba55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182040794/182040794 [00:03<00:00, 58936212.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64275384/64275384 [00:01<00:00, 59081180.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "svhn_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((48,48)),\n",
    "    transforms.Grayscale()\n",
    "])\n",
    "\n",
    "SVHN_train_dataset = datasets.SVHN(root='./', split='train', transform=svhn_transform, download=True)\n",
    "SVHN_test_dataset = datasets.SVHN(root='./', split='test', transform=svhn_transform, download=True)\n",
    "\n",
    "sv_train_loader = DataLoader(dataset=SVHN_train_dataset, batch_size=128, shuffle=True)\n",
    "sv_test_loader = DataLoader(dataset=SVHN_test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apRfwcHqQAyR",
    "outputId": "6b275bf7-5017-48aa-feac-c6c082a22b8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48, 48])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVHN_train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "OVlsly0sQC44",
    "outputId": "24528e23-65b0-4106-f444-22e161be25d4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(SVHN_train_dataset[170][0][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okBbDZxfQEs4",
    "outputId": "995a9e8d-9362-4f41-b07d-6c0ca983df1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 10.464043617248535\n"
     ]
    }
   ],
   "source": [
    "test(convnet2, sv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "-HJndGHNQHmw"
   },
   "outputs": [],
   "source": [
    "class SvhnNet(nn.Module):\n",
    "  def __init__(self, pretrain_model):\n",
    "    super().__init__()\n",
    "    self.pretrain = pretrain_model # 학습된 모델을 self.pretrain에 저장\n",
    "    # 우리가 받은 pretrain_model의 parameter를 고정\n",
    "    for param in self.pretrain.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "    self.add_model = nn.Sequential(\n",
    "        nn.Linear(in_features=64*3*3, out_features=256),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(in_features=256, out_features=10),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "\n",
    "  def forward(self, inp):\n",
    "    with torch.no_grad(): # 기울기 학습 안하도록 함\n",
    "      cnn_result = self.pretrain(inp)\n",
    "    flatten = torch.flatten(cnn_result, 1)\n",
    "    result = self.add_model(flatten)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "zrNhnOvMQKyY"
   },
   "outputs": [],
   "source": [
    "svhn_net = SvhnNet(convnet2.CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxDCK3h5QQ3R",
    "outputId": "6ef3e781-5fca-4763-ed1b-c5c041b73cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             160\n",
      "              ReLU-2           [-1, 16, 48, 48]               0\n",
      "            Conv2d-3           [-1, 16, 48, 48]           2,320\n",
      "              ReLU-4           [-1, 16, 48, 48]               0\n",
      "         MaxPool2d-5           [-1, 16, 24, 24]               0\n",
      "            Conv2d-6           [-1, 32, 24, 24]           4,640\n",
      "              ReLU-7           [-1, 32, 24, 24]               0\n",
      "            Conv2d-8           [-1, 32, 24, 24]           9,248\n",
      "              ReLU-9           [-1, 32, 24, 24]               0\n",
      "        MaxPool2d-10           [-1, 32, 12, 12]               0\n",
      "           Conv2d-11           [-1, 64, 12, 12]          18,496\n",
      "             ReLU-12           [-1, 64, 12, 12]               0\n",
      "           Conv2d-13           [-1, 64, 12, 12]          36,928\n",
      "             ReLU-14           [-1, 64, 12, 12]               0\n",
      "           Conv2d-15           [-1, 64, 12, 12]          36,928\n",
      "             ReLU-16           [-1, 64, 12, 12]               0\n",
      "        MaxPool2d-17             [-1, 64, 3, 3]               0\n",
      "           Linear-18                  [-1, 256]         147,712\n",
      "             ReLU-19                  [-1, 256]               0\n",
      "          Dropout-20                  [-1, 256]               0\n",
      "           Linear-21                   [-1, 10]           2,570\n",
      "          Softmax-22                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 259,002\n",
      "Trainable params: 150,282\n",
      "Non-trainable params: 108,720\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.23\n",
      "Params size (MB): 0.99\n",
      "Estimated Total Size (MB): 3.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "svhn_net.to(device)\n",
    "summary(svhn_net, (1,48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBuMyATjQSfh",
    "outputId": "df3aadf6-d45e-45dc-c9ed-b3180ec26076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset SVHN\n",
       "    Number of datapoints: 73257\n",
       "    Root location: ./\n",
       "    Split: train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Resize(size=(48, 48), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               Grayscale(num_output_channels=1)\n",
       "           )"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVHN_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "aqZv8pJCRj-X"
   },
   "outputs": [],
   "source": [
    "# 데이터셋에서 일부만 가져오기\n",
    "from torch.utils.data import random_split\n",
    "svhn_train_1, svhn_train_2 = random_split(SVHN_train_dataset, [1000, 72257])\n",
    "sv_train_loader2 = DataLoader(dataset=svhn_train_1,\n",
    "                              batch_size=128,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05gBGZCuRmA_",
    "outputId": "7e3050f6-764f-4b2b-8ff6-dd0089013547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :1/10\n",
      "train_accuracy : 23.952659606933594\n",
      "epochs :2/10\n",
      "train_accuracy : 43.54669189453125\n",
      "epochs :3/10\n",
      "train_accuracy : 46.472007751464844\n",
      "epochs :4/10\n",
      "train_accuracy : 49.780906677246094\n",
      "epochs :5/10\n",
      "train_accuracy : 50.594482421875\n",
      "epochs :6/10\n",
      "train_accuracy : 53.27954864501953\n",
      "epochs :7/10\n",
      "train_accuracy : 54.42210006713867\n",
      "epochs :8/10\n",
      "train_accuracy : 56.7413330078125\n",
      "epochs :9/10\n",
      "train_accuracy : 57.388370513916016\n",
      "epochs :10/10\n",
      "train_accuracy : 59.393638610839844\n",
      "학습 시간 : 11분 2031429596160411901718980754129728727207423633162187101652082753489596089392691064391513580291720150491103091581050906094922722866087356384249146844184114531675462237683712초\n"
     ]
    }
   ],
   "source": [
    "train(svhn_net, sv_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjrOJlQ0Rnli"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufCb5k07ZQsu"
   },
   "source": [
    "# 학습된 ResNet 18을 이용해서 매우 적은 숫자의 FashionMNIST를 학습시키자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "Yohvfa-lZRLc"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), # tensor형태로 변환\n",
    "    transforms.Resize(224) # 224x224 이미지로 변환\n",
    "])\n",
    "\n",
    "train_dataset = FashionMNIST('./', transform=fashion_mnist_transforms, train=True, download=True)\n",
    "test_dataset = FashionMNIST('./', transform=fashion_mnist_transforms, train=False, download=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size = 256,\n",
    "                         shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "thkzqeeJZRcE"
   },
   "outputs": [],
   "source": [
    "# random_split\n",
    "\n",
    "train_dataset1, train_dataset2 = random_split(train_dataset, [100, 59900])\n",
    "train_loader2 = DataLoader(dataset = train_dataset1,\n",
    "                           batch_size = 128,\n",
    "                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2rTakSLZX37",
    "outputId": "01074e2d-d3dc-4ccc-8924-d2f776e71c9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f7f6c8adf40>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4b11ivczZZbE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTVTXX2rZbn2"
   },
   "source": [
    "# ResNet18Transfer Learning\n",
    "\n",
    "학습된 데이터를 가져오자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "EiyUMxQ9ZeXz",
    "outputId": "7ab93df0-a803-4e44-b097-0831075f7a4b"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-89647a1db5ae>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrenet18_pretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moretrainded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.models' has no attribute 'renet18'"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "resnet18_pretrained = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPnyrFZyaCFj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
